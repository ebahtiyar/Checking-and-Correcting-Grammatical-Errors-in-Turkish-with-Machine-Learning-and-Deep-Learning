{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_punc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO+ylHfrmNU3zvqwuNsmDSf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ebahtiyar/Checking-and-Correcting-Grammatical-Errors-in-Turkish-with-Machine-Learning-and-Deep-Learning/blob/main/model_punc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44RwiG7tPHmE"
      },
      "outputs": [],
      "source": [
        "  !apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.insert(0,\"/content/drive/My Drive/project\")\n",
        "import os\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import sqlite_functions as sql\n",
        "import functions as f\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import preproccessing as pre\n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense,Embedding,Bidirectional,dot,Activation,concatenate,RepeatVector, TimeDistributed\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import random\n",
        "from tensorflow import keras\n",
        "import punc_preprocessing as punc\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import re\n",
        "#data = pre.load_data(\"/content/drive/My Drive/project/database.db\",\"Total_senteces_F1\")"
      ],
      "metadata": {
        "id": "s6nBSIM2PN-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "921822d0-2277-4b5c-8546-8ed956fcceec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def control2(data,exc_punc):\n",
        "    #exc_punc = '\"!…'\n",
        "    s = list()\n",
        "    se = list()\n",
        "\n",
        "    for i in data:\n",
        "        adding = True\n",
        "        for j in i:\n",
        "            if j in exc_punc:\n",
        "                adding = False\n",
        "        if adding:\n",
        "            se.append(i)\n",
        "        \n",
        "    f1 = '.,?'\n",
        "    for i in se:\n",
        "        c = 0\n",
        "        for j in i:\n",
        "            if (j in f1):\n",
        "               c =  c + 1\n",
        "            \n",
        "        if c > 1:\n",
        "           s.append(i)\n",
        "        \n",
        "    return s"
      ],
      "metadata": {
        "id": "4kpux1CuQ_To"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_input2(data,exc_punc,balanced):\n",
        "\n",
        "    \n",
        "    input_data = list()\n",
        "    temp = list()\n",
        "    adding = True\n",
        "    for line in data:\n",
        "        adding , s = f.punctuation_filter(line)\n",
        "        if adding:\n",
        "           temp.append(s)\n",
        "           \n",
        "           \n",
        "    input_data = control2(temp,exc_punc)\n",
        "    \n",
        "    if balanced:\n",
        "        t_per = punc.n_punc(input_data,\":\")\n",
        "        c_pre = punc.n_punc(input_data,\";\")\n",
        "        com = punc.n_punc(input_data, \",\")\n",
        "        per = punc.n_punc(input_data, \".\")\n",
        "        que = punc.n_punc(input_data, \"?\")\n",
        "        \n",
        "        total = random.choices(que,k = 250000) + random.choices(per,k = 100000) + random.choices(com,k = 200000)\n",
        "        total = f.unique(total)\n",
        "        return total\n",
        "    else:\n",
        "        input_data = f.unique(input_data)\n",
        "        return input_data"
      ],
      "metadata": {
        "id": "Ompd7SaRRA8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_output2(input_data):\n",
        "    input = []\n",
        "    output_data = list()\n",
        "    for line in input_data:\n",
        "        output_s = \"\"\n",
        "        words = line.split()\n",
        "        for word in words:\n",
        "            if word[len(word)-1].isalpha():\n",
        "               output_s = output_s + \"EMP \"\n",
        "            \n",
        "            else:\n",
        "               if word[len(word)-1] == \",\":\n",
        "                  output_s = output_s + \"COM \"\n",
        "               if word[len(word) -1] == \".\":\n",
        "                  output_s = output_s + \"PER \"\n",
        "               if word[len(word) -1]  == \"?\":\n",
        "                  output_s = output_s + \"QUE \"\n",
        "        s = re.sub(r'[^\\w\\s]', '', line)\n",
        "        input.append(s)    \n",
        "        output_data.append(output_s)\n",
        "    \n",
        "    return input,output_data"
      ],
      "metadata": {
        "id": "LFaxbQbYREBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = punc.load_data(\"/content/drive/My Drive/project/database.db\",\"Total_senteces_F1\")\n",
        "intp = []\n",
        "for i in data:\n",
        "    k = i.split()\n",
        "    if len(k) < 30:\n",
        "        intp.append(i)\n",
        "input_data = list()\n",
        "output_data = list()"
      ],
      "metadata": {
        "id": "sFcNjBWOdtIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = generator_input2(intp,exc_punc = '\"!…:;',balanced = False )\n",
        "que = punc.n_punc(intp, \"?\")\n",
        "data = data + que \n",
        "data = f.unique(data)"
      ],
      "metadata": {
        "id": "EveCjv8mRS9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(que)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FQcLx5Qhr2Q",
        "outputId": "6229e289-8956-402a-b7be-6ccb8b98115e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "152556"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdaoYgSlhc0R",
        "outputId": "d64df8a8-69b9-4ecc-cb3a-919d0edaa0ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "817597"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data,output_data = generator_output2(data)"
      ],
      "metadata": {
        "id": "A1g5fXhORTDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = {\"Training Sentences\":input_data,\"Labels\":output_data}\n",
        "data_df = pd.DataFrame(s)\n",
        "data_df.sample(50)\n",
        "x_train , x_test , y_train , y_test = train_test_split(input_data,output_data,test_size=0.1) "
      ],
      "metadata": {
        "id": "8mLMjG00H1kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "p4ArYrPVhnWY",
        "outputId": "42f32db1-3282-4acb-f29c-c445fde0efd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-97b90ff2-1b76-4a42-b4ab-c1617bd60d8a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Sentences</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>193382</th>\n",
              "      <td>Bu yaşta bir çocuk bunları uyduramaz anlattıkl...</td>\n",
              "      <td>EMP EMP EMP EMP EMP COM EMP PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>695192</th>\n",
              "      <td>Yetenekli hırslı ve çok çalışkandı</td>\n",
              "      <td>COM EMP EMP EMP PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244755</th>\n",
              "      <td>Dalgalı derin yüzeyin altındaki serin ve sakin...</td>\n",
              "      <td>COM EMP EMP EMP EMP EMP EMP EMP PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326001</th>\n",
              "      <td>Geleceğe yönelik tüm korkularınızdan uzaklaşma...</td>\n",
              "      <td>EMP EMP EMP EMP COM EMP EMP EMP PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540001</th>\n",
              "      <td>Peki işi gerçekten de bu noktaya taşımış olabi...</td>\n",
              "      <td>EMP EMP EMP EMP EMP EMP EMP EMP QUE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97b90ff2-1b76-4a42-b4ab-c1617bd60d8a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-97b90ff2-1b76-4a42-b4ab-c1617bd60d8a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-97b90ff2-1b76-4a42-b4ab-c1617bd60d8a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                       Training Sentences                                Labels\n",
              "193382  Bu yaşta bir çocuk bunları uyduramaz anlattıkl...      EMP EMP EMP EMP EMP COM EMP PER \n",
              "695192                 Yetenekli hırslı ve çok çalışkandı                  COM EMP EMP EMP PER \n",
              "244755  Dalgalı derin yüzeyin altındaki serin ve sakin...  COM EMP EMP EMP EMP EMP EMP EMP PER \n",
              "326001  Geleceğe yönelik tüm korkularınızdan uzaklaşma...  EMP EMP EMP EMP COM EMP EMP EMP PER \n",
              "540001  Peki işi gerçekten de bu noktaya taşımış olabi...  EMP EMP EMP EMP EMP EMP EMP EMP QUE "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(sentences):\n",
        "    # Create tokenizer\n",
        "    text_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='<OOV>')\n",
        "    # Fit texts\n",
        "    text_tokenizer.fit_on_texts(sentences)\n",
        "    return text_tokenizer.texts_to_sequences(sentences), text_tokenizer"
      ],
      "metadata": {
        "id": "DeGHkH51o7ZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_train_tokenized, in_train_tokenizer = tokenize(x_train) \n",
        "out_train_tokenized, out_train_tokenizer = tokenize(y_train) \n",
        "print('Maximum length input sentence: {}'.format(len(max(in_train_tokenized,key=len))))\n",
        "print('Maximum length output sentence: {}'.format(len(max(out_train_tokenized,key=len))))\n",
        "\n",
        "in_test_tokenized, in_test_tokenizer = tokenize(x_test)\n",
        "out_test_tokenized, out_test_tokenizer = tokenize(y_test)\n",
        "\n",
        "in_vocab = len(in_train_tokenizer.word_index) + 1\n",
        "out_vocab = len(out_train_tokenizer.word_index) + 1\n",
        "print(\"w vocabulary is of {} unique words\".format(in_vocab))\n",
        "print(\"r vocabulary is of {} unique words\".format(out_vocab))\n",
        "\n",
        "in_vocab_val = len(in_test_tokenizer.word_index) + 1\n",
        "out_vocab_val = len(out_test_tokenizer.word_index) + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cl5sE-IOo7vG",
        "outputId": "ff9deffa-5746-4916-a288-1a867f21dbe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum length input sentence: 29\n",
            "Maximum length output sentence: 29\n",
            "w vocabulary is of 410993 unique words\n",
            "r vocabulary is of 6 unique words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "max_in_len = int(len(max(in_train_tokenized,key=len)))\n",
        "max_out_len = int(len(max(out_train_tokenized,key=len)))\"\"\n",
        "\"\"\"\n",
        "max_in_len = 34\n",
        "max_out_len = 34\n",
        "in_pad_sentence = pad_sequences(in_train_tokenized, max_in_len, padding = \"post\")\n",
        "out_pad_sentence = pad_sequences(out_train_tokenized, max_out_len, padding = \"post\")\n",
        "\n",
        "in_pad_sentence = in_pad_sentence.reshape(*in_pad_sentence.shape, 1)\n",
        "out_pad_sentence = out_pad_sentence.reshape(*out_pad_sentence.shape, 1)\n",
        "\n",
        "max_in_vlen = int(len(max(in_test_tokenized,key=len)))\n",
        "max_out_vlen = int(len(max(out_test_tokenized,key=len)))\n",
        "in_pad_vsentence = pad_sequences(in_test_tokenized, max_in_len, padding = \"post\")\n",
        "out_pad_vsentence = pad_sequences(out_test_tokenized, max_out_len, padding = \"post\")\n",
        "\n",
        "in_pad_vsentence = in_pad_vsentence.reshape(*in_pad_vsentence.shape, 1)\n",
        "out_pad_vsentence = out_pad_vsentence.reshape(*out_pad_vsentence.shape, 1)"
      ],
      "metadata": {
        "id": "BrR5j1c9o92O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = 'my_best_model.epoch{epoch:02d}-loss{val_loss:.2f}.hdf5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=filepath, \n",
        "                             monitor='val_loss',\n",
        "                             verbose=1, \n",
        "                             save_best_only=True,\n",
        "                             mode='min')\n",
        "\n",
        "callbacks = [checkpoint]\n",
        "input_sequence = Input(shape=(max_in_len,))\n",
        "embedding = Embedding(input_dim=in_vocab, output_dim=128,)(input_sequence)\n",
        "encoder = Bidirectional(LSTM(64, return_sequences=False))(embedding)\n",
        "r_vec = RepeatVector(max_out_len)(encoder)\n",
        "decoder = Bidirectional(LSTM(64, return_sequences=True, dropout=0.3))(r_vec)\n",
        "logits = TimeDistributed(Dense(out_vocab))(decoder)\n",
        "\n",
        "model = Model(input_sequence, Activation('softmax')(logits))\n",
        "model.compile(loss=sparse_categorical_crossentropy,\n",
        "              optimizer=Adam(1e-3),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "WYEKReNcpAeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_results = model.fit(in_pad_sentence, out_pad_sentence, validation_split = 0.2, epochs=5 , callbacks=callbacks,batch_size = 256,shuffle=True)"
      ],
      "metadata": {
        "id": "brF4AQpWpCKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3dcce1a-925a-427a-d44d-9371fa4f19fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "2300/2300 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9708\n",
            "Epoch 00001: val_loss improved from 0.10049 to 0.09948, saving model to my_best_model.epoch01-loss0.10.hdf5\n",
            "2300/2300 [==============================] - 567s 246ms/step - loss: 0.0780 - accuracy: 0.9708 - val_loss: 0.0995 - val_accuracy: 0.9659\n",
            "Epoch 2/5\n",
            "2300/2300 [==============================] - ETA: 0s - loss: 0.0670 - accuracy: 0.9751\n",
            "Epoch 00002: val_loss did not improve from 0.09948\n",
            "2300/2300 [==============================] - 551s 240ms/step - loss: 0.0670 - accuracy: 0.9751 - val_loss: 0.1003 - val_accuracy: 0.9663\n",
            "Epoch 3/5\n",
            "2300/2300 [==============================] - ETA: 0s - loss: 0.0580 - accuracy: 0.9784\n",
            "Epoch 00003: val_loss did not improve from 0.09948\n",
            "2300/2300 [==============================] - 546s 237ms/step - loss: 0.0580 - accuracy: 0.9784 - val_loss: 0.1026 - val_accuracy: 0.9662\n",
            "Epoch 4/5\n",
            "2300/2300 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9810\n",
            "Epoch 00004: val_loss did not improve from 0.09948\n",
            "2300/2300 [==============================] - 550s 239ms/step - loss: 0.0515 - accuracy: 0.9810 - val_loss: 0.1075 - val_accuracy: 0.9661\n",
            "Epoch 5/5\n",
            "2300/2300 [==============================] - ETA: 0s - loss: 0.0452 - accuracy: 0.9831\n",
            "Epoch 00005: val_loss did not improve from 0.09948\n",
            "2300/2300 [==============================] - 556s 242ms/step - loss: 0.0452 - accuracy: 0.9831 - val_loss: 0.1111 - val_accuracy: 0.9659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score =model1.evaluate(in_pad_vsentence, out_pad_vsentence)\n",
        "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
      ],
      "metadata": {
        "id": "y9lAnxzoBRDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7daedf8-9d68-4d54-8fb5-797db5855112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2555/2555 [==============================] - 47s 17ms/step - loss: 0.1532 - accuracy: 0.9513\n",
            "Test loss: 0.15315859019756317 / Test accuracy: 0.9513112306594849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1=load_model(\"/content/my_best_model.epoch01-loss0.10.hdf5\")"
      ],
      "metadata": {
        "id": "r4ZP0nNx0d2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = \"Kim bunlara Çocuk katilleri diye haykıracak\"\n",
        "prediction(model,sample.lower(),in_train_tokenizer,out_train_tokenizer).strip()\n"
      ],
      "metadata": {
        "id": "K_nMWIhL56fs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7cb0d9ea-b40f-4e09-e25d-986b7daf57cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'kim bunlara çocuk katilleri diye haykıracak?'"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = sample.lower()"
      ],
      "metadata": {
        "id": "MElosfEB9Wub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  sample_pad = []\n",
        "  for word in sample.split():\n",
        "      if word in in_train_tokenizer.word_index:\n",
        "         sample_pad.append(in_train_tokenizer.word_index[word])\n",
        "      else:\n",
        "         sample_pad.append(1)\n",
        "\n",
        "  sample_pad = pad_sequences([sample_pad], maxlen=34, padding='post')\n",
        "  pred = model.predict(sample_pad)\n",
        "  y_id_to_word = {value: key for key, value in out_train_tokenizer.word_index.items()}\n",
        "  y_id_to_word[0] = '<PAD>'\n",
        "  puncs = [y_id_to_word[np.argmax(x)] for x in pred[0]]"
      ],
      "metadata": {
        "id": "piJhPLWW9Mpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(model,sample,in_train_tokenizer,out_train_tokenizer):\n",
        "  sample_pad = []\n",
        "  for word in sample.split():\n",
        "      if word in in_train_tokenizer.word_index:\n",
        "         sample_pad.append(in_train_tokenizer.word_index[word])\n",
        "      else:\n",
        "         sample_pad.append(1)\n",
        "\n",
        "  sample_pad = pad_sequences([sample_pad], maxlen=34, padding='post')\n",
        "  pred = model.predict(sample_pad)\n",
        "  y_id_to_word = {value: key for key, value in out_train_tokenizer.word_index.items()}\n",
        "  y_id_to_word[0] = '<PAD>'\n",
        "  puncs = [y_id_to_word[np.argmax(x)] for x in pred[0]]\n",
        "  new_sentence = \"\"\n",
        "  words = sample.split()\n",
        "  for n,word in enumerate(words):\n",
        "     if puncs[n] == \"emp\":\n",
        "        new_sentence = new_sentence + word + \" \"\n",
        "     if puncs[n] == \"com\":\n",
        "        new_sentence = new_sentence + word + \", \"\n",
        "     if puncs[n] == \"per\":\n",
        "        new_sentence = new_sentence + word + \".  \"    \n",
        "     if puncs[n] == \"que\":\n",
        "        new_sentence = new_sentence + word + \"?  \"\n",
        "     if puncs[n] == \"<PAD>\":\n",
        "        continue\n",
        "  return new_sentence"
      ],
      "metadata": {
        "id": "ExYcHIAbGZaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.save('/content/drive/My Drive/project/savedd_model/model_punc_2.h5')"
      ],
      "metadata": {
        "id": "N3sL3GPfBcAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('/content/drive/MyDrive/project/savedd_model/model_punc_1.h5')"
      ],
      "metadata": {
        "id": "Auow1CimBeZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/project/variables/in_train_tokenizer_punc', 'wb') as handle:\n",
        "    pickle.dump(in_train_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open('/content/drive/MyDrive/project/variables/out_train_tokenizer_punc', 'wb') as handle:\n",
        "    pickle.dump(out_train_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "cZrISncE-44C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('/content/drive/My Drive/project/variables/in_train_tokenizer_punc', 'rb') as handle:\n",
        "    in_train_tokenizer = pickle.load(handle)\n",
        "\n",
        "\n",
        "with open('/content/drive/My Drive/project/variables/out_train_tokenizer_punc', 'rb') as handle:\n",
        "    out_train_tokenizer = pickle.load(handle)"
      ],
      "metadata": {
        "id": "t3rlVMSg-5Aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Score**"
      ],
      "metadata": {
        "id": "4lQfsOw92CwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = punc.load_data(\"/content/drive/My Drive/project/test.db\",\"test_sentences\")\n",
        "intp = []\n",
        "for i in data:\n",
        "    k = i.split()\n",
        "    if len(k) < 30:\n",
        "        intp.append(i)\n",
        "input_data = list()\n",
        "output_data = list()"
      ],
      "metadata": {
        "id": "E7Rh9yU7I6I3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = generator_input2(intp,exc_punc = '\"!…:;',balanced = False )\n",
        "que = punc.n_punc(intp, \"?\")\n",
        "data = data[:13000] + que \n",
        "data = f.unique(data)"
      ],
      "metadata": {
        "id": "TsWgQgNlJBPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tYY-0JiL9sB",
        "outputId": "7b5e1357-3688-4baf-ff11-a2c69a18748f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20343"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test,y_test = generator_output2(data)"
      ],
      "metadata": {
        "id": "Kcc7ssF-JQCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction_label(model,sample,in_train_tokenizer,out_train_tokenizer):\n",
        "  sample_pad = []\n",
        "  for word in sample.split():\n",
        "      if word in in_train_tokenizer.word_index:\n",
        "         sample_pad.append(in_train_tokenizer.word_index[word])\n",
        "      else:\n",
        "         sample_pad.append(1)\n",
        "\n",
        "  sample_pad = pad_sequences([sample_pad], maxlen=34, padding='post')\n",
        "  pred = model.predict(sample_pad)\n",
        "  y_id_to_word = {value: key for key, value in out_train_tokenizer.word_index.items()}\n",
        "  y_id_to_word[0] = '<PAD>'\n",
        "  puncs = [y_id_to_word[np.argmax(x)] for x in pred[0]]\n",
        "  return puncs"
      ],
      "metadata": {
        "id": "LsG7GYBh2Eth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = list(zip(x_test,y_test))\n",
        "test_x = []\n",
        "test_y = []\n",
        "for i,j in test:\n",
        "    if len(i.split()) == len(j.split()):\n",
        "       test_x.append(i)\n",
        "       test_y.append(j)\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "eV-8fGg5_QAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_label = []\n",
        "\n",
        "for line in test_x:\n",
        "    pred_label.append(prediction_label(model,line.lower(),in_train_tokenizer,out_train_tokenizer))\n",
        "test_label = []\n",
        "for line in test_y:\n",
        "    line = line.lower()\n",
        "    test_label.append(line.split())"
      ],
      "metadata": {
        "id": "8hq6T-Hv2JFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_l = []\n",
        "\n",
        "for pred in pred_label:\n",
        "    t = []\n",
        "    for i in pred:\n",
        "        if i != \"<PAD>\":\n",
        "           t.append(i)\n",
        "    pred_l.append(t)"
      ],
      "metadata": {
        "id": "VWrhIsS13cAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = list(zip(test_label,pred_l))\n",
        "test_input = []\n",
        "test_label = []\n",
        "for i,j in y:\n",
        "    if len(i) == len(j):\n",
        "       test_input.append(i)\n",
        "       test_label.append(j)"
      ],
      "metadata": {
        "id": "zrNw24Y1VoSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iec49HVfN1sv",
        "outputId": "a7967ea3-e149-4753-bd53-3a345467d268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▌                        | 10 kB 20.8 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 43 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=b339eda4be133a8ee2bd35fe42a2736aa1f082f45997e250b3ec3733186a3cb2\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import classification_report, f1_score\n",
        "report = classification_report(test_input ,test_label)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92DPV6Y14J75",
        "outputId": "8a3ad169-c361-48c2-bb55-a21f5cab37a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: emp seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: com seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: que seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: per seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          er       0.96      0.98      0.97     12426\n",
            "          mp       0.42      0.29      0.34     36083\n",
            "          om       0.52      0.17      0.25     19041\n",
            "          ue       0.97      0.93      0.95      6875\n",
            "\n",
            "   micro avg       0.64      0.43      0.52     74425\n",
            "   macro avg       0.72      0.59      0.63     74425\n",
            "weighted avg       0.59      0.43      0.48     74425\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2xvATCSQNfBY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}